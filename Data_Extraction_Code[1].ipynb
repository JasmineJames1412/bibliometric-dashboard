{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8e33682-f027-45fe-ad45-f8d16a7d83fa",
   "metadata": {},
   "source": [
    "# Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11426b1e-8710-4a5b-83c0-824997385463",
   "metadata": {},
   "source": [
    "## Author Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca7b3b52-760e-42f3-89e6-418509433001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the author's name:  Rajendra Prasad\n",
      "Enter the author's affiliation (or keyword):  Professor Dean, Amity University Haryana\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author not found. Check the name or affiliation keyword.\n"
     ]
    }
   ],
   "source": [
    "from scholarly import scholarly\n",
    "import pandas as pd\n",
    "\n",
    "def get_author_details(author_name, author_affiliation):\n",
    "    search_query = scholarly.search_author(author_name)\n",
    "    for author in search_query:\n",
    "        if author_affiliation.lower() in author.get(\"affiliation\", \"\").lower():\n",
    "            return scholarly.fill(author)\n",
    "    return None\n",
    "\n",
    "def get_publication_details(publication):\n",
    "    return scholarly.fill(publication)\n",
    "\n",
    "def save_to_excel(publication_data, all_years, filename=\"author_details_output.xlsx\"):\n",
    "    # Prepare final data list with desired column order\n",
    "    final_data = []\n",
    "\n",
    "    for row in publication_data:\n",
    "        base_data = {\n",
    "            \"title\": row[\"title\"],\n",
    "            \"authors\": row[\"authors\"],\n",
    "            \"journal\": row[\"journal\"],\n",
    "            \"publication date\": row[\"publication date\"],\n",
    "            \"total citation\": row[\"total citation\"],\n",
    "            \"volume\": row[\"volume\"],\n",
    "            \"publisher\": row[\"publisher\"],\n",
    "        }\n",
    "\n",
    "        # Add year-wise citation data in correct order\n",
    "        for year in all_years:\n",
    "            base_data[str(year)] = row.get(\"citations_per_year\", {}).get(year, 0)\n",
    "\n",
    "        # Finally, add the description\n",
    "        base_data[\"description\"] = row[\"description\"]\n",
    "\n",
    "        final_data.append(base_data)\n",
    "\n",
    "    # Create DataFrame and save\n",
    "    df = pd.DataFrame(final_data)\n",
    "    df.to_excel(filename, index=False)\n",
    "    print(f\"\\nData saved to {filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    author_name = input(\"Enter the author's name: \")\n",
    "    author_affiliation = input(\"Enter the author's affiliation (or keyword): \")\n",
    "    details = get_author_details(author_name, author_affiliation)\n",
    "\n",
    "    if details:\n",
    "        print(\"\\nFetching publication details...\")\n",
    "        publications = details.get(\"publications\", [])\n",
    "\n",
    "        data = []\n",
    "        all_years = set()\n",
    "\n",
    "        for pub in publications[:290]:  # You can increase the number if needed\n",
    "            detailed_pub = get_publication_details(pub)\n",
    "            bib = detailed_pub.get(\"bib\", {})\n",
    "            cites_per_year = detailed_pub.get(\"cites_per_year\", {})\n",
    "\n",
    "            all_years.update(cites_per_year.keys())\n",
    "\n",
    "            pub_year = bib.get(\"pub_year\", \"N/A\")\n",
    "            pub_month = bib.get(\"pub_month\", \"N/A\")\n",
    "            pub_day = bib.get(\"pub_day\", \"N/A\")\n",
    "            pub_date = f\"{pub_year}/{pub_month}/{pub_day}\" if pub_year != \"N/A\" and pub_month != \"N/A\" and pub_day != \"N/A\" else pub_year\n",
    "\n",
    "            data.append({\n",
    "                \"title\": bib.get(\"title\", \"Unknown Title\"),\n",
    "                \"authors\": bib.get(\"author\", \"N/A\"),\n",
    "                \"journal\": bib.get(\"journal\", \"N/A\"),\n",
    "                \"publication date\": pub_date,\n",
    "                \"total citation\": detailed_pub.get(\"num_citations\", \"N/A\"),\n",
    "                \"volume\": bib.get(\"volume\", \"N/A\"),\n",
    "                \"publisher\": bib.get(\"publisher\", \"N/A\"),\n",
    "                \"description\": bib.get(\"abstract\", \"N/A\"),\n",
    "                \"citations_per_year\": cites_per_year\n",
    "            })\n",
    "\n",
    "        save_to_excel(data, sorted(all_years))\n",
    "\n",
    "    else:\n",
    "        print(\"Author not found. Check the name or affiliation keyword.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bee538-20bc-40ee-9a19-6405223ca14a",
   "metadata": {},
   "source": [
    "## Article Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d4c7e1-67a2-4224-a518-319377dbd32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "def scrape_scholar_articles(query, num_pages):\n",
    "    articles = []\n",
    "    page = 0\n",
    "    while page < num_pages:\n",
    "        url = f\"https://scholar.google.com/scholar?start={page*10}&q={query}&hl=en&as_sdt=0,5\"\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        results = soup.find_all(\"div\", class_=\"gs_ri\")\n",
    "\n",
    "        for result in results:\n",
    "            title = result.find(\"h3\", class_=\"gs_rt\").text\n",
    "            authors = result.find(\"div\", class_=\"gs_a\").text\n",
    "            link_tag = result.find(\"a\")\n",
    "            link = link_tag[\"href\"] if link_tag else \"N/A\"\n",
    "\n",
    "            citation_tag = result.find(\"div\", class_=\"gs_fl\").find_all(\"a\")\n",
    "            citation_text = next((a.text for a in citation_tag if \"Cited by\" in a.text), \"Cited by 0\")\n",
    "            citations = int(citation_text.replace(\"Cited by\", \"\").strip())\n",
    "\n",
    "            articles.append({\n",
    "                \"Title\": title,\n",
    "                \"Authors\": authors,\n",
    "                \"Link\": link,\n",
    "                \"Citations\": citations\n",
    "            })\n",
    "\n",
    "        page += 1\n",
    "\n",
    "    return articles\n",
    "\n",
    "def save_to_excel(articles, filename):\n",
    "    df = pd.DataFrame(articles)\n",
    "    df.to_excel(filename, index=False)\n",
    "\n",
    "def browse_folder():\n",
    "    folder_path = filedialog.askdirectory()\n",
    "    entry_folder.delete(0, tk.END)\n",
    "    entry_folder.insert(tk.END, folder_path)\n",
    "\n",
    "def scrape_articles():\n",
    "    query = entry_query.get()\n",
    "    num_pages = int(entry_pages.get())\n",
    "\n",
    "    articles = scrape_scholar_articles(query, num_pages)\n",
    "\n",
    "    folder_path = entry_folder.get()\n",
    "    if folder_path:\n",
    "        filename = f\"{folder_path}/scholar_articles.xlsx\"\n",
    "    else:\n",
    "        filename = \"Health_articles.xlsx\"\n",
    "\n",
    "    save_to_excel(articles, filename)\n",
    "    label_status.config(text=\"Extraction complete. Data saved to scholar_articles.xlsx.\")\n",
    "\n",
    "# Create the main window\n",
    "window = tk.Tk()\n",
    "window.title(\"Google Scholar Scraper\")\n",
    "window.geometry(\"400x250\")\n",
    "\n",
    "# Create input fields and labels\n",
    "label_query = tk.Label(window, text=\"Article Title or Keyword:\")\n",
    "label_query.pack()\n",
    "entry_query = tk.Entry(window, width=40)\n",
    "entry_query.pack()\n",
    "\n",
    "label_pages = tk.Label(window, text=\"Number of Pages:\")\n",
    "label_pages.pack()\n",
    "entry_pages = tk.Entry(window, width=40)\n",
    "entry_pages.pack()\n",
    "\n",
    "label_folder = tk.Label(window, text=\"Output Folder (optional):\")\n",
    "label_folder.pack()\n",
    "entry_folder = tk.Entry(window, width=40)\n",
    "entry_folder.pack()\n",
    "\n",
    "# Create browse button\n",
    "button_browse = tk.Button(window, text=\"Browse\", command=browse_folder)\n",
    "button_browse.pack()\n",
    "\n",
    "# Create extract button\n",
    "button_extract = tk.Button(window, text=\"Extract Data\", command=scrape_articles)\n",
    "button_extract.pack()\n",
    "\n",
    "# Create status label\n",
    "label_status = tk.Label(window, text=\"\")\n",
    "label_status.pack()\n",
    "\n",
    "# Run the main window loop\n",
    "window.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
